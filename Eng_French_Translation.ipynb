{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eng_French_Translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvddk6w/RWIRRgxLO0U2Ob",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahul-dsml/Myprojects/blob/main/Eng_French_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "L-3rpXCIMutK"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "bu3AFXXgMlh0"
      },
      "outputs": [],
      "source": [
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token= 0\n",
        "EOS_token = 1"
      ],
      "metadata": {
        "id": "ruHHRFVWOGSx"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lang:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.W2I = { 'SOS':SOS_token, 'EOS': EOS_token}\n",
        "    self.I2W= {SOS_token: 'SOS', EOS_token: 'EOS'}\n",
        "    self.W2C = {}\n",
        "    self.n_words = 2\n",
        "  \n",
        "  def addSentence(self, s):\n",
        "    for word in s.split(\" \"):\n",
        "      self.addWord(word)\n",
        "\n",
        "  def addWord(self, w):\n",
        "    if w not in self.W2I:\n",
        "      self.W2I[w]= self.n_words\n",
        "      self.W2C[w]= 1\n",
        "      self.I2W[self.n_words] = w\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.W2C[w]+=1\n",
        "  \n",
        "  def printAllWords(self):\n",
        "    words= list(self.W2I.keys())\n",
        "    for word in words:\n",
        "      print(word)"
      ],
      "metadata": {
        "id": "jq2Zk3KfOVpy"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L= Lang('Eng')"
      ],
      "metadata": {
        "id": "JdODS5TDPfzu"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L.addWord('NLP')\n",
        "L.addSentence('I am learning Machine Translation')"
      ],
      "metadata": {
        "id": "PuYBtWD5QW4b"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L.printAllWords()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6108y0pdQ8z6",
        "outputId": "56805db8-fcb7-42a8-cb40-5a18debbeed0"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SOS\n",
            "EOS\n",
            "NLP\n",
            "I\n",
            "am\n",
            "learning\n",
            "Machine\n",
            "Translation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unicode2ascii(s):\n",
        "  return \"\".join(\n",
        "      c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c) != 'Mn'\n",
        "  )"
      ],
      "metadata": {
        "id": "vnpNo7ZqRBFb"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizeString(s):\n",
        "  s= unicode2ascii(s.lower().strip())\n",
        "  s= re.sub(r'([.!?])',r'\\1',s)\n",
        "  s= re.sub(r'[^a-zA-Z.!?]+',' ',s)\n",
        "  return s"
      ],
      "metadata": {
        "id": "STbsLwCESIUY"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normalizeString('saudgfeyugxce7y978d6y9'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FmC5s06UPUV",
        "outputId": "d894d325-1752-4372-8c8e-8476081f1859"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saudgfeyugxce y d y \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the data file"
      ],
      "metadata": {
        "id": "DQMLfu9VVUxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Read the data file\n",
        "def readLangs():\n",
        "  lines= open('/content/drive/MyDrive/NLP/eng-fra.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "  pairs= [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "  input_lang= Lang('eng')\n",
        "  output_lang= Lang('fra')\n",
        "  return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "8xy8DSjKVQ_G"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "I,O,P= readLangs()"
      ],
      "metadata": {
        "id": "CbDGmItDVCxa"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-Hk5ruEWPkM",
        "outputId": "7496eff4-1ea7-466f-d275-4acab23e4839"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['go.', 'va !'],\n",
              " ['run!', 'cours !'],\n",
              " ['run!', 'courez !'],\n",
              " ['wow!', 'ca alors !'],\n",
              " ['fire!', 'au feu !']]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(I,O,P):\n",
        "  Max_Len= 0\n",
        "  for pair in P:\n",
        "    I.addSentence(pair[0])\n",
        "    O.addSentence(pair[1])\n",
        "    Max_Len = max(Max_Len, len(pair[0].split()), len(pair[1].split()))\n",
        "  return I, O, Max_Len"
      ],
      "metadata": {
        "id": "mIQUD9swWZe9"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang, output_lang, Max_Len= prepareData(I,O,P)"
      ],
      "metadata": {
        "id": "BbYGzgIiWlQ7"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Max_Len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYR6gYzSX_p4",
        "outputId": "c5356585-6074-421b-cf9c-ae1c2444737b"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang.n_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NzgmM-tYG7V",
        "outputId": "e51074be-85d7-43c0-f002-4a2c39790062"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20753"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_lang.n_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY7SX8mpYJM9",
        "outputId": "778b77b6-4c00-4b07-959a-680eaa193c01"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29481"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_lang.printAllWords()"
      ],
      "metadata": {
        "id": "3SgtS0yRYLes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(random.choice(P))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHSnQ4TpYOnW",
        "outputId": "6f1ed7ea-9211-4d70-8c43-c9457859ae05"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['her belief in god is very firm.', 'c est une fervente croyante.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs= P"
      ],
      "metadata": {
        "id": "ScAI1YwxYqEt"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder RNN"
      ],
      "metadata": {
        "id": "grHNm8wBcibC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, vocabSize, hidden_size):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.E = nn.Embedding(vocabSize,hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "  def forward(self, input, hidden):\n",
        "    emb= self.E(input).view(1,1,-1)\n",
        "    output,hidden = self.gru(emb, hidden)\n",
        "    return output, hidden\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(2,1,self.hidden_size, device= device)"
      ],
      "metadata": {
        "id": "QsrbTr39YwXc"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder RNN"
      ],
      "metadata": {
        "id": "a51cMEgydwJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, vocabSize, max_length = Max_Len):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = vocabSize\n",
        "    self.max_length = Max_Len\n",
        "    self.E = nn.Embedding(self.output_size, self.hidden_size)\n",
        "    self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
        "    self.attn_combine = nn.Linear(self.hidden_size*3, self.hidden_size)\n",
        "    self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "    self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "  def forward(self, input, hidden, encoder_outputs):\n",
        "    emb = self.E(input).view(1,1,-1)\n",
        "    attn_w = F.softmax(self.attn(torch.cat((emb[0], hidden[0]), 1)), dim=1)\n",
        "    attn_A = torch.bmm(attn_w.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "    output = torch.cat((emb[0], attn_A[0]),1)\n",
        "    output = self.attn_combine(output.unsqueeze(0))\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    output = F.log_softmax(self.out(output[0]), dim= 1)\n",
        "    return output, hidden, attn_w\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1,1,self.hidden_size, device= device)\n"
      ],
      "metadata": {
        "id": "S--RqmosdnNg"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder RNN Helper Functions"
      ],
      "metadata": {
        "id": "7762V3O4heW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, s):\n",
        "  return [lang.W2I[w] for w in s.split()]\n",
        "\n",
        "def tensorFromSentence(lang,s):\n",
        "  idx = indexesFromSentence(lang, s)\n",
        "  idx.append(EOS_token)\n",
        "  return torch.tensor(idx, dtype = torch.long, device = device).view(-1,1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "  input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "  output_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "  return (input_tensor, output_tensor)"
      ],
      "metadata": {
        "id": "_voLR1-Ee_ib"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "4vt7j5DDiwA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_fn, max_length= Max_Len):\n",
        "  encoder_hidden = encoder.initHidden()\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  input_length = input_tensor.size(0)\n",
        "  target_length = target_tensor.size(0)\n",
        "  encoder_outputs = torch.zeros(max_length, 2*encoder.hidden_size, device=device)\n",
        "  loss = 0\n",
        "  for ei in range(input_length):\n",
        "    encoder_output, encoder_hidden = encoder(\n",
        "        input_tensor[ei], encoder_hidden)\n",
        "    out_reshaped = encoder_output.view(1,1,2,encoder.hidden_size)\n",
        "    out_forward = out_reshaped[:,:,0,:]\n",
        "    out_backward = out_reshaped[:,:,1,:]\n",
        "    encoder_outputs[ei] = torch.cat((out_forward[0,0], out_backward[0,0]),0)\n",
        "  decoder_input = torch.tensor([[SOS_token]], device= device)\n",
        "  h_reshaped = encoder_hidden.view(1,2,1,encoder.hidden_size)\n",
        "  decoder_hidden = h_reshaped[:,0,:,:]\n",
        "\n",
        "  for di in range(target_length):\n",
        "    decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "        decoder_input, decoder_hidden, encoder_outputs\n",
        "    )\n",
        "    topv, topi = decoder_output.topk(1)\n",
        "    decoder_input = topi.squeeze().detach()\n",
        "    loss+= loss_fn(decoder_output, target_tensor[di])\n",
        "    if decoder_input.item() == EOS_token:\n",
        "      break\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    return loss.item()/target_length"
      ],
      "metadata": {
        "id": "38-1rIKOiuhK"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "lDTyjqPzmEwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIter(encoder, decoder, n_iters, lr = 0.001):\n",
        "  totalLoss= 0\n",
        "  encoder_optimizer = optim.SGD(encoder.parameters(), lr=lr)\n",
        "  decoder_optimizer = optim.SGD(decoder.parameters(), lr=lr)\n",
        "  training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
        "  loss_fn = nn.NLLLoss()\n",
        "  for iter in range(n_iters):\n",
        "    training_pair = training_pairs[iter]\n",
        "    input_tensor = training_pair[0]\n",
        "    target_tensor = training_pair[1]\n",
        "    loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_fn)\n",
        "    totalLoss+= loss\n",
        "    print(totalLoss/(iter+1))\n"
      ],
      "metadata": {
        "id": "kmMfHWQkl6ml"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NMT Training"
      ],
      "metadata": {
        "id": "7667FV9nnaHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)"
      ],
      "metadata": {
        "id": "z4ZAIHGwnSxb"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainIter(encoder, decoder, 100, lr = 0.001)"
      ],
      "metadata": {
        "id": "AJq88IMnnc1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of Neural Machine Translation"
      ],
      "metadata": {
        "id": "FuC3Lzb5rTc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, s, max_length= Max_Len):\n",
        "  with torch.no_grad():\n",
        "    input_tensor = tensorFromSentence(input_lang, s)\n",
        "    input_length = input_tensor.size()[0]\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_outputs = torch.zeros(max_length, 2*encoder.hidden_size, device=device)\n",
        "    \n",
        "    for ei in range(input_length):\n",
        "      encoder_output, encoder_hidden = encoder(\n",
        "          input_tensor[ei], encoder_hidden)\n",
        "      out_reshaped = encoder_output.view(1,1,2,encoder.hidden_size)\n",
        "      out_forward = out_reshaped[:,:,0,:]\n",
        "      out_backward = out_reshaped[:,:,1,:]\n",
        "      encoder_outputs[ei] = torch.cat((out_forward[0,0], out_backward[0,0]),0)\n",
        "    decoder_input = torch.tensor([[SOS_token]], device= device)\n",
        "    h_reshaped = encoder_hidden.view(1,2,1,encoder.hidden_size)\n",
        "    decoder_hidden = h_reshaped[:,0,:,:]\n",
        "\n",
        "    decoder_words = []\n",
        "    decoder_att = torch.zeros(max_length, max_length)\n",
        "\n",
        "    for di in range(max_length):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "        decoder_input, decoder_hidden, encoder_outputs)\n",
        "      decoder_att[di] = decoder_attention.data\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      if topi.item()== EOS_token:\n",
        "        decoder_words.append('<EOS>')\n",
        "        break\n",
        "      else:\n",
        "        decoder_words.append(output_lang.I2W[topi.item()])\n",
        "      decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    return decoder_words\n"
      ],
      "metadata": {
        "id": "z6WkpAYfncs0"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(encoder, decoder, pairs[0][0]), pairs[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsGiGq4vncjA",
        "outputId": "b99a6039-9a32-482b-c768-fb814c1d5589"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['corrompt', 'grandement', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.', 'atlanta', 'remerciement.'] va !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P0hRi0LZtjKj"
      },
      "execution_count": 144,
      "outputs": []
    }
  ]
}